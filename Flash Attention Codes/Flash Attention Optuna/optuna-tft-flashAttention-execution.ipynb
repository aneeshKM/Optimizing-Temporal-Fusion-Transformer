{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZSQm4kVe6aY",
    "outputId": "bf95f08c-1966-4241-f8c2-808e1ea4fd49"
   },
   "outputs": [],
   "source": [
    "# ─── Cell 1: Patch the mean warning and silence logging ───\n",
    "import warnings, numpy as np, logging\n",
    "from gluonts.model import forecast as _fm\n",
    "\n",
    "# Silence the specific UserWarning\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r\"The mean prediction is not stored in the forecast data; the median is being returned instead\\. This behaviour may change in the future\\.\"\n",
    ")\n",
    "# Disable all WARNING and below from all loggers (including GluonTS internals)\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "# Override .mean on the original classes (in-place)\n",
    "def _silent_mean(self):\n",
    "    fd = getattr(self, \"_forecast_dict\", {})\n",
    "    if \"mean\" in fd:\n",
    "        return fd[\"mean\"]\n",
    "    if hasattr(self, \"samples\"):\n",
    "        return np.median(self.samples, axis=0)\n",
    "    return self.quantile(\"p50\")\n",
    "\n",
    "_fm.SampleForecast.mean   = property(_silent_mean)\n",
    "_fm.QuantileForecast.mean = property(_silent_mean)\n",
    "# ────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Ea7HqpYmtXac"
   },
   "outputs": [],
   "source": [
    "# ─── Cell 2: Core imports ───\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from local.gluonts.torch.model.tft import TemporalFusionTransformerEstimator\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "# ─────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "baqN6PWMn7FV"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "prediction_length = 24\n",
    "context_length = 168\n",
    "window_length = context_length + prediction_length\n",
    "freq = \"1h\"\n",
    "\n",
    "def get_electricity_dataset(csv_path: str, total_samples=500_000):\n",
    "    df = pd.read_csv(csv_path, index_col=0)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    # Encode categorical ID\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"categorical_id\"] = label_encoder.fit_transform(df[\"categorical_id\"].astype(str))\n",
    "\n",
    "    # Limit data to Jan 1 – Sep 1, 2014 (i.e., days_from_start < 1339)\n",
    "    full_range_df = df[df[\"days_from_start\"] < 1339]\n",
    "\n",
    "    # Sample sliding windows over full range\n",
    "    def sample_windows(subset_df):\n",
    "        samples = []\n",
    "        for entity_id, group in subset_df.groupby(\"id\"):\n",
    "            group = group.sort_values(\"date\")\n",
    "            if len(group) < window_length:\n",
    "                continue\n",
    "\n",
    "            scaler = StandardScaler().fit(group[[\"power_usage\", \"hour\", \"day_of_week\", \"t\"]].values)\n",
    "            target_scaler = StandardScaler().fit(group[[\"power_usage\"]].values)\n",
    "\n",
    "            features = scaler.transform(group[[\"power_usage\", \"hour\", \"day_of_week\", \"t\"]].values)\n",
    "            targets = target_scaler.transform(group[[\"power_usage\"]].values).flatten().astype(np.float32)\n",
    "\n",
    "            feat_hour = features[:, 1].astype(np.float32)\n",
    "            feat_dow = features[:, 2].astype(np.float32)\n",
    "            feat_time = features[:, 3].astype(np.float32)\n",
    "\n",
    "            static_cat = [group[\"categorical_id\"].iloc[0]]\n",
    "            dates = group[\"date\"].values\n",
    "\n",
    "            for i in range(0, len(group) - window_length + 1):\n",
    "                samples.append({\n",
    "                    FieldName.START: dates[i],\n",
    "                    FieldName.TARGET: targets[i:i + window_length],\n",
    "                    FieldName.FEAT_STATIC_CAT: static_cat,\n",
    "                    FieldName.FEAT_DYNAMIC_REAL: [\n",
    "                        feat_hour[i:i + window_length],\n",
    "                        feat_dow[i:i + window_length],\n",
    "                        feat_time[i:i + window_length],\n",
    "                    ],\n",
    "                })\n",
    "\n",
    "        return samples\n",
    "\n",
    "    # Step 1: All possible windows up to Sep 1\n",
    "    all_samples = sample_windows(full_range_df)\n",
    "\n",
    "    # Step 2: Shuffle and take 500,000 total\n",
    "    np.random.shuffle(all_samples)\n",
    "    all_samples = all_samples[:total_samples]\n",
    "\n",
    "    # Step 3: Split into 450k train / 50k val\n",
    "    train_samples = all_samples[:450_000]\n",
    "    val_samples = all_samples[450_000:]\n",
    "\n",
    "    # Step 4: Test set = fixed last 7 days (same as official code)\n",
    "    test_df = df[df[\"days_from_start\"] >= 1332]\n",
    "    test_samples = sample_windows(test_df)\n",
    "\n",
    "    train_ds = ListDataset(train_samples, freq=freq)\n",
    "    val_ds = ListDataset(val_samples, freq=freq)\n",
    "    test_ds = ListDataset(test_samples, freq=freq)\n",
    "\n",
    "    return train_ds, val_ds, test_ds, freq, prediction_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5MGhJYHs-Bx",
    "outputId": "9acd8aaf-fb61-4bca-db7c-1ef6772a6cf2"
   },
   "outputs": [],
   "source": [
    "file_path = \"../Dataset/Electricity/hourly_electricity.csv\"  # Adjust if it's in a subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "VYJr5LKtn7FW"
   },
   "outputs": [],
   "source": [
    "# ─── Cell 4: Load data & set precision ───\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "train_ds, val_ds, test_ds, freq, prediction_length = get_electricity_dataset(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # ── 1) Sample hyperparameters ──\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256])\n",
    "    num_heads  = trial.suggest_categorical(\"num_heads\",  [1,   4  ])\n",
    "    # hidden_dim = trial.suggest_categorical(\"hidden_dim\",[80, 160, 240])\n",
    "\n",
    "    # ── 2) Build estimator with sampled batch_size ──\n",
    "    print(\"Batch Size: \", batch_size)\n",
    "    print(\"Num heads: \",num_heads)\n",
    "    # print(\"Hidden dim: \",hidden_dim)\n",
    "    \n",
    "    estimator = TemporalFusionTransformerEstimator(\n",
    "        freq=freq,\n",
    "        prediction_length=prediction_length,\n",
    "        context_length=168,\n",
    "        static_cardinalities=[370],\n",
    "        dynamic_dims=[3],\n",
    "        quantiles=[0.1, 0.5, 0.9],\n",
    "        hidden_dim=160,\n",
    "        num_heads=num_heads,\n",
    "        batch_size=batch_size,\n",
    "        num_batches_per_epoch= int(len(train_ds) // batch_size),\n",
    "        trainer_kwargs={\n",
    "            \"accelerator\": \"gpu\",\n",
    "            \"devices\": [0],\n",
    "            \"max_epochs\": 3,\n",
    "            \"precision\": \"bf16-mixed\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Optional: print model summary\n",
    "    module  = estimator.create_lightning_module()\n",
    "    summary = ModelSummary(module, max_depth=1)\n",
    "    print(summary)\n",
    "\n",
    "    # ── 3) Time & memory for training ──\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    predictor = estimator.train(\n",
    "        training_data=train_ds,\n",
    "        validation_data=val_ds\n",
    "    )\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "        train_peak_mem = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "    train_time = time.time() - t0\n",
    "    print(f\"[bs={batch_size}] Training: {train_time:.3f}s, Peak GPU mem: {train_peak_mem:.1f} MB\")\n",
    "\n",
    "    # ── 4) Time & memory for inference ──\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    # (keeps your existing precision setting)\n",
    "    with torch.amp.autocast(\"cuda\"):\n",
    "        f_it, ts_it = make_evaluation_predictions(\n",
    "            dataset=test_ds,\n",
    "            predictor=predictor,\n",
    "            num_samples=100,\n",
    "        )\n",
    "        forecasts = list(f_it)\n",
    "        tss       = list(ts_it)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "        inf_peak_mem = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "    inf_time = time.time() - t1\n",
    "    print(f\"[bs={batch_size}] Inference: {inf_time:.3f}s, Peak GPU mem: {inf_peak_mem:.1f} MB\")\n",
    "\n",
    "    # ── 5) Time evaluation and return metric ──\n",
    "    t2 = time.time()\n",
    "    evaluator    = Evaluator(quantiles=[0.5], num_workers=0)\n",
    "    agg_metrics, _ = evaluator(tss, forecasts)\n",
    "    eval_time = time.time() - t2\n",
    "    print(f\"[bs={batch_size}] Evaluation time: {eval_time:.3f}s\")\n",
    "\n",
    "    return agg_metrics[\"MASE\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "c0dCKgUvn7FX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size:  256\n",
      "Num heads:  4\n",
      "  | Name  | Type                           | Params | Mode  | In sizes                                                                                 | Out sizes                     \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | TemporalFusionTransformerModel | 858 K  | train | [[1, 168], [1, 168], [1, 1], [1, 1], [1, 192, 7], [1, 192, 0], [1, 168, 0], [1, 168, 0]] | [[[1, 24, 3]], [1, 1], [1, 1]]\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "858 K     Trainable params\n",
      "0         Non-trainable params\n",
      "858 K     Total params\n",
      "3.435     Total estimated model params size (MB)\n",
      "250       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akm9999/.local/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /share/apps/pyenv/py3.9/lib/python3.9/site-packages/ ...\n",
      "/home/akm9999/.local/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /scratch/akm9999/Project/FlashAttention/lightning_logs/version_60858/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc224e548e56450e86d5507120c86715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bs=256] Training: 1125.634s, Peak GPU mem: 871.8 MB\n",
      "[bs=256] Inference: 41.955s, Peak GPU mem: 365.5 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running evaluation: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 3179it [00:10, 317.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 6358it [00:20, 317.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 9542it [00:30, 318.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 12737it [00:40, 318.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 15932it [00:50, 318.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 19133it [01:00, 319.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 22334it [01:10, 319.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 25128it [01:20, 305.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 25128it [01:20, 305.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 28336it [01:30, 310.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 31558it [01:40, 314.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 34780it [01:50, 316.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 38003it [02:00, 318.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 41226it [02:10, 319.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 44445it [02:20, 319.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 47664it [02:30, 320.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 53505it [02:48, 317.66it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bs=256] Evaluation time: 168.750s\n",
      "Batch Size:  128\n",
      "Num heads:  1\n",
      "  | Name  | Type                           | Params | Mode  | In sizes                                                                                 | Out sizes                     \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | TemporalFusionTransformerModel | 858 K  | train | [[1, 168], [1, 168], [1, 1], [1, 1], [1, 192, 7], [1, 192, 0], [1, 168, 0], [1, 168, 0]] | [[[1, 24, 3]], [1, 1], [1, 1]]\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "858 K     Trainable params\n",
      "0         Non-trainable params\n",
      "858 K     Total params\n",
      "3.435     Total estimated model params size (MB)\n",
      "250       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akm9999/.local/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /share/apps/pyenv/py3.9/lib/python3.9/site-packages/ ...\n",
      "/home/akm9999/.local/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /scratch/akm9999/Project/FlashAttention/lightning_logs/version_60858/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3ace9b97a0411f8e13d1caf73bb1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bs=128] Training: 1400.961s, Peak GPU mem: 450.2 MB\n",
      "[bs=128] Inference: 42.358s, Peak GPU mem: 183.6 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running evaluation: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 3167it [00:10, 316.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 6357it [00:20, 317.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 9547it [00:30, 318.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 12736it [00:40, 318.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 15925it [00:50, 317.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 19088it [01:01, 302.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 22287it [01:11, 307.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 25486it [01:21, 311.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 28684it [01:31, 313.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 31882it [01:41, 315.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 35074it [01:51, 316.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 38284it [02:01, 317.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 41494it [02:11, 318.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 44695it [02:21, 318.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 47903it [02:31, 319.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 53505it [02:49, 316.27it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bs=128] Evaluation time: 169.494s\n",
      "Batch Size:  64\n",
      "Num heads:  4\n",
      "  | Name  | Type                           | Params | Mode  | In sizes                                                                                 | Out sizes                     \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | TemporalFusionTransformerModel | 858 K  | train | [[1, 168], [1, 168], [1, 1], [1, 1], [1, 192, 7], [1, 192, 0], [1, 168, 0], [1, 168, 0]] | [[[1, 24, 3]], [1, 1], [1, 1]]\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "858 K     Trainable params\n",
      "0         Non-trainable params\n",
      "858 K     Total params\n",
      "3.435     Total estimated model params size (MB)\n",
      "250       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akm9999/.local/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /share/apps/pyenv/py3.9/lib/python3.9/site-packages/ ...\n",
      "/home/akm9999/.local/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /scratch/akm9999/Project/FlashAttention/lightning_logs/version_60858/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52464f2c229948a0aa31f32ac86deaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bs=64] Training: 2003.377s, Peak GPU mem: 240.5 MB\n",
      "[bs=64] Inference: 46.063s, Peak GPU mem: 112.1 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running evaluation: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 3202it [00:10, 320.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 6404it [00:20, 319.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 9537it [00:31, 303.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 9537it [00:31, 303.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 12666it [00:41, 306.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 15812it [00:51, 309.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 18958it [01:01, 311.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 22149it [01:11, 313.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 25336it [01:21, 314.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 25336it [01:21, 314.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 28500it [01:31, 315.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 31673it [01:41, 315.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 34846it [01:51, 316.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 38019it [02:01, 316.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 41192it [02:11, 316.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 44362it [02:21, 316.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 47140it [02:31, 302.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 47140it [02:31, 302.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 50307it [02:41, 306.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 53505it [02:51, 311.88it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bs=64] Evaluation time: 171.884s\n",
      "Batch Size:  128\n",
      "Num heads:  4\n",
      "  | Name  | Type                           | Params | Mode  | In sizes                                                                                 | Out sizes                     \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | TemporalFusionTransformerModel | 858 K  | train | [[1, 168], [1, 168], [1, 1], [1, 1], [1, 192, 7], [1, 192, 0], [1, 168, 0], [1, 168, 0]] | [[[1, 24, 3]], [1, 1], [1, 1]]\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "858 K     Trainable params\n",
      "0         Non-trainable params\n",
      "858 K     Total params\n",
      "3.435     Total estimated model params size (MB)\n",
      "250       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akm9999/.local/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /share/apps/pyenv/py3.9/lib/python3.9/site-packages/ ...\n",
      "/home/akm9999/.local/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /scratch/akm9999/Project/FlashAttention/lightning_logs/version_60858/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fe67fffafd498e946ca1d8a3efe55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bs=128] Training: 1402.072s, Peak GPU mem: 450.6 MB\n",
      "[bs=128] Inference: 40.753s, Peak GPU mem: 193.6 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running evaluation: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 3190it [00:10, 318.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 6380it [00:20, 318.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 9570it [00:30, 318.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 12772it [00:40, 319.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 15974it [00:50, 319.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 19168it [01:00, 319.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 22374it [01:10, 319.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 25580it [01:20, 319.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 28767it [01:31, 305.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 31958it [01:41, 309.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 35149it [01:51, 312.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 38340it [02:01, 314.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 41528it [02:11, 315.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 44706it [02:21, 316.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 47881it [02:31, 316.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 53505it [02:49, 316.15it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bs=128] Evaluation time: 169.565s\n",
      "Batch Size:  64\n",
      "Num heads:  1\n",
      "  | Name  | Type                           | Params | Mode  | In sizes                                                                                 | Out sizes                     \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | TemporalFusionTransformerModel | 858 K  | train | [[1, 168], [1, 168], [1, 1], [1, 1], [1, 192, 7], [1, 192, 0], [1, 168, 0], [1, 168, 0]] | [[[1, 24, 3]], [1, 1], [1, 1]]\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "858 K     Trainable params\n",
      "0         Non-trainable params\n",
      "858 K     Total params\n",
      "3.435     Total estimated model params size (MB)\n",
      "250       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akm9999/.local/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /share/apps/pyenv/py3.9/lib/python3.9/site-packages/ ...\n",
      "/home/akm9999/.local/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /scratch/akm9999/Project/FlashAttention/lightning_logs/version_60858/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b7bd77b40649c08868db8aef9c00e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bs=64] Training: 1987.662s, Peak GPU mem: 240.4 MB\n",
      "[bs=64] Inference: 48.903s, Peak GPU mem: 112.1 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running evaluation: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 3166it [00:10, 316.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 6346it [00:20, 317.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 9527it [00:30, 317.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 12710it [00:40, 317.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 15895it [00:50, 318.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 19080it [01:00, 318.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 22261it [01:10, 318.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 25442it [01:20, 317.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 28619it [01:31, 304.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 31799it [01:41, 308.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 34981it [01:51, 311.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 38163it [02:01, 313.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 41347it [02:11, 314.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 44531it [02:21, 315.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 47719it [02:31, 316.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 53505it [02:49, 315.35it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bs=64] Evaluation time: 169.990s\n",
      "Batch Size:  256\n",
      "Num heads:  1\n",
      "  | Name  | Type                           | Params | Mode  | In sizes                                                                                 | Out sizes                     \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | TemporalFusionTransformerModel | 858 K  | train | [[1, 168], [1, 168], [1, 1], [1, 1], [1, 192, 7], [1, 192, 0], [1, 168, 0], [1, 168, 0]] | [[[1, 24, 3]], [1, 1], [1, 1]]\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "858 K     Trainable params\n",
      "0         Non-trainable params\n",
      "858 K     Total params\n",
      "3.435     Total estimated model params size (MB)\n",
      "250       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akm9999/.local/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /share/apps/pyenv/py3.9/lib/python3.9/site-packages/ ...\n",
      "/home/akm9999/.local/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /scratch/akm9999/Project/FlashAttention/lightning_logs/version_60858/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f074736f422c428785fa6ccb061f1913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4abeb9545a542be96cf028e9ff6a70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97be2e8959d940a89e050a3acedce9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bs=256] Training: 1126.620s, Peak GPU mem: 860.8 MB\n",
      "[bs=256] Inference: 39.522s, Peak GPU mem: 355.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running evaluation: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 3197it [00:10, 319.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 6407it [00:20, 320.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 9617it [00:30, 320.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 12834it [00:40, 320.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 16051it [00:50, 321.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 19262it [01:00, 320.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 22486it [01:10, 321.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 25710it [01:20, 321.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 28923it [01:31, 308.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 32135it [01:41, 312.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 35353it [01:51, 315.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 38571it [02:01, 316.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 41774it [02:11, 317.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 44999it [02:21, 319.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 48224it [02:31, 319.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running evaluation: 53505it [02:47, 318.69it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bs=256] Evaluation time: 168.204s\n",
      "total time taken: 10327.435197591782\n",
      "Best trial:\n",
      "FrozenTrial(number=3, state=TrialState.COMPLETE, values=[0.8949014631189218], datetime_start=datetime.datetime(2025, 5, 9, 4, 2, 20, 407256), datetime_complete=datetime.datetime(2025, 5, 9, 4, 29, 13, 422558), params={'batch_size': 128, 'num_heads': 4}, user_attrs={}, system_attrs={'search_space': {'batch_size': [64, 128, 256], 'num_heads': [1, 4]}, 'grid_id': 3}, intermediate_values={}, distributions={'batch_size': CategoricalDistribution(choices=(64, 128, 256)), 'num_heads': CategoricalDistribution(choices=(1, 4))}, trial_id=3, value=None)\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 6: Run Optuna optimization ───\n",
    "from optuna.samplers import GridSampler\n",
    "# ─── Cell 6: Run Optuna optimization ───\n",
    "search_space = {\n",
    "    \"batch_size\": [64, 128, 256],\n",
    "    \"num_heads\":  [1,   4],\n",
    "}\n",
    "\n",
    "# 2. Create the GridSampler\n",
    "sampler = GridSampler(search_space)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "start = time.time()\n",
    "study.optimize(objective, n_trials=6, timeout=36000)\n",
    "end = time.time() - start\n",
    "\n",
    "print(\"total time taken:\", end)\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial)\n",
    "# ─────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Grab the best hyperparameters\n",
    "best = study.best_trial.params\n",
    "num_heads    = best[\"num_heads\"]\n",
    "# hidden_dim   = best[\"hidden_dim\"]\n",
    "batch_size   = best[\"batch_size\"]\n",
    "\n",
    "\n",
    "# collect into a dict\n",
    "best_params = {\n",
    "    \"num_heads\":    num_heads,\n",
    "    # \"hidden_dim\":   hidden_dim,\n",
    "    \"batch_size\":   batch_size,\n",
    "}\n",
    "\n",
    "# pretty‑print each name and value\n",
    "for name, value in best_params.items():\n",
    "    print(f\"{name:12s}: {value}\")\n",
    "\n",
    "# # 2) Build a new estimator with full‑training epochs\n",
    "# best_estimator = TemporalFusionTransformerEstimator(\n",
    "#     freq=\"1H\",\n",
    "#     prediction_length=24,\n",
    "#     context_length=168,\n",
    "#     hidden_dim=hidden_dim,         # 6 * 20 = 120\n",
    "#     num_heads=num_heads,           # 6\n",
    "#     dropout_rate=dropout_rate,     # ~0.26\n",
    "#     lr=lr,\n",
    "#     weight_decay=weight_decay,\n",
    "#     batch_size=64,\n",
    "#     num_batches_per_epoch=50,\n",
    "#     trainer_kwargs={\n",
    "#         \"accelerator\": \"gpu\",\n",
    "#         \"max_epochs\": 1,           # full training run\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# # 3) Train on train_ds (and val_ds if you want early stopping)\n",
    "# best_predictor = best_estimator.train(\n",
    "#     training_data=train_ds,\n",
    "#     validation_data=val_ds\n",
    "# )\n",
    "\n",
    "# forecast_it, ts_it = make_evaluation_predictions(\n",
    "#     dataset=test_ds,\n",
    "#     predictor=best_predictor,\n",
    "#     num_samples=100,\n",
    "# )\n",
    "# agg_metrics, item_metrics = Evaluator()(ts_it, forecast_it)\n",
    "\n",
    "# print(\"Test set metrics:\", agg_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# choose an output directory\n",
    "save_path = Path(\"model_dir\")\n",
    "\n",
    "# this will create model_dir/ with all the predictor files inside\n",
    "best_predictor.serialize(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7346220,
     "sourceId": 11703799,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0552146e1e2143be9a6679bb1fddf806": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8202d7c94854bd4a2f681935cc1b44d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d6ca43b42da34c318fe6f4d70b0fecb7",
      "value": 1
     }
    },
    "086e05f80448427db7b47a29f69bccc9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d305562ee354b2580cf368dd88e770d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a94aa42f2ec45cba4517e28c82bde65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "474267174073429ba51590d9f1974c91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "48f5e4ad166c4c778a7373c8591ff865": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0ab2373a2db4630a4edc00d85aa12ee",
      "placeholder": "​",
      "style": "IPY_MODEL_b9f2f319a0004d99a4eb387d1f77dd56",
      "value": " 2/2 [00:00&lt;00:00, 12.99it/s]"
     }
    },
    "4933e732da1e418eba11e5619eb7e3eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "58464e6c01b245f7abbff7e2bbc0c554": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb832112cb4c470ca9d549af461fc421",
      "placeholder": "​",
      "style": "IPY_MODEL_af337a177cb34155b1a21b1047ccee8e",
      "value": "Sanity Checking DataLoader 0: 100%"
     }
    },
    "64dd9ff2ecbe4836b78658eb8a2dcea6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_086e05f80448427db7b47a29f69bccc9",
      "placeholder": "​",
      "style": "IPY_MODEL_da9a4f632f814177ab12597b60536c83",
      "value": "Epoch 0: "
     }
    },
    "6a6540cc7b684cb2a51e870f0517157c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71562f76030448e4b6fd3f1d8726677f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3dbc24c64b64e8aa1b36a0c79ef8797",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7b92ede60f184532856eba206a8a8924",
      "value": 2
     }
    },
    "77b470430c804255b830bf0b8226fb9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e93b1345a2df484b8d851015c0eabeb2",
      "placeholder": "​",
      "style": "IPY_MODEL_9342cbb8eaf34a66a622512b2b14ec36",
      "value": " 780/? [00:34&lt;00:00, 22.43it/s]"
     }
    },
    "7b92ede60f184532856eba206a8a8924": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7e4bc3df7d0b483898daf526b09cf6d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d305562ee354b2580cf368dd88e770d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aeba3f6f9c6d4af9a41d3370656b4761",
      "value": 1
     }
    },
    "9342cbb8eaf34a66a622512b2b14ec36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9dce0819b6c14aadb5ce9f53d5071930": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58464e6c01b245f7abbff7e2bbc0c554",
       "IPY_MODEL_71562f76030448e4b6fd3f1d8726677f",
       "IPY_MODEL_48f5e4ad166c4c778a7373c8591ff865"
      ],
      "layout": "IPY_MODEL_4933e732da1e418eba11e5619eb7e3eb"
     }
    },
    "a0ab2373a2db4630a4edc00d85aa12ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aeba3f6f9c6d4af9a41d3370656b4761": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "af337a177cb34155b1a21b1047ccee8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0fb38b258a641598210f731a829aa1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "b6fdb262a4374f29833c72ca9d81ab1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d3ae955091af4cb19666e808c19a2d7d",
       "IPY_MODEL_0552146e1e2143be9a6679bb1fddf806",
       "IPY_MODEL_77b470430c804255b830bf0b8226fb9a"
      ],
      "layout": "IPY_MODEL_b0fb38b258a641598210f731a829aa1d"
     }
    },
    "b8202d7c94854bd4a2f681935cc1b44d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9f2f319a0004d99a4eb387d1f77dd56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb832112cb4c470ca9d549af461fc421": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3dbc24c64b64e8aa1b36a0c79ef8797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c65f5305fe484514b87cf351475998ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0a5479fd8d84609bc70365a297e5fd6",
      "placeholder": "​",
      "style": "IPY_MODEL_6a6540cc7b684cb2a51e870f0517157c",
      "value": " 7800/? [10:46&lt;00:00, 12.06it/s, v_num=0, val_loss=0.141, train_loss=0.197]"
     }
    },
    "d2ae68bdefe74f9fa35723d0b5fc0e47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3ae955091af4cb19666e808c19a2d7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a94aa42f2ec45cba4517e28c82bde65",
      "placeholder": "​",
      "style": "IPY_MODEL_d2ae68bdefe74f9fa35723d0b5fc0e47",
      "value": "Validation DataLoader 0: "
     }
    },
    "d6ca43b42da34c318fe6f4d70b0fecb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "da9a4f632f814177ab12597b60536c83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ddddb34722804fed9f8fd92d7babdab7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_64dd9ff2ecbe4836b78658eb8a2dcea6",
       "IPY_MODEL_7e4bc3df7d0b483898daf526b09cf6d9",
       "IPY_MODEL_c65f5305fe484514b87cf351475998ea"
      ],
      "layout": "IPY_MODEL_474267174073429ba51590d9f1974c91"
     }
    },
    "e93b1345a2df484b8d851015c0eabeb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0a5479fd8d84609bc70365a297e5fd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
